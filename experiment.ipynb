{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "from config import NUM_CLIENTS, DEVICE\n",
    "from model import VGG16\n",
    "from main import simulate_cifar\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T10:36:27.614441995Z",
     "start_time": "2023-06-09T10:36:26.715906952Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Centralize training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataloader import load_cifars\n",
    "trainloaders, valloaders, testloader = load_cifars(1)\n",
    "\n",
    "trainloader = trainloaders[0]\n",
    "valloader = valloaders[0]\n",
    "net = VGG16().to(DEVICE)\n",
    "\n",
    "for epoch in range(10):\n",
    "    net.train_epoch(trainloader, 1)\n",
    "    loss, accuracy = net.test(valloader)\n",
    "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "\n",
    "loss, accuracy = net.test(testloader)\n",
    "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-09T08:51:30.955817356Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fed avg with parameter initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import torch\n",
    "from numpy import array\n",
    "\n",
    "print(tensor(array(0)).shape)\n",
    "print(torch.Tensor(array(0)).shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T10:39:09.914325850Z",
     "start_time": "2023-06-09T10:39:09.910070626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-09T10:38:48.585745613Z",
     "start_time": "2023-06-09T10:36:44.393443656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-06-09 17:36:45,461 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-06-09 17:36:47,002\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "INFO flwr 2023-06-09 17:36:47,603 | app.py:180 | Flower VCE: Ray initialized with resources: {'node:10.10.12.34': 1.0, 'CPU': 20.0, 'memory': 4786640487.0, 'object_store_memory': 2393320243.0}\n",
      "INFO flwr 2023-06-09 17:36:47,604 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-06-09 17:36:47,605 | server.py:269 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-06-09 17:36:47,605 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-06-09 17:36:47,605 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-06-09 17:36:47,606 | server.py:218 | fit_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=82654)\u001B[0m [Client 8] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2023-06-09 17:37:07,040 | ray_client_proxy.py:87 | Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 10.10.12.34, ID: efc616ad18ed9b7fc1436ea140a65ab128bcac37f2d9dbae16ef51f0) where the task (task ID: 7fc10dc253cbb71054b56bf8898478e5ed0465d501000000, name=launch_and_fit, pid=82654, memory used=1.24GB) was running was 14.73GB / 15.39GB (0.956622), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: efa7a3e129b58274c47fdffe6c7e742ce8b4b3a1c176d82a83172758) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.10.12.34`. To see the logs of the worker, use `ray logs worker-efa7a3e129b58274c47fdffe6c7e742ce8b4b3a1c176d82a83172758*out -ip 10.10.12.34. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "8425\t2.84\t/snap/pycharm-professional/336/jbr/bin/java -classpath /snap/pycharm-professional/336/lib/app.jar:/s...\n",
      "82657\t1.24\tray::launch_and_fit\n",
      "82654\t1.24\tray::launch_and_fit\n",
      "82656\t1.19\tray::launch_and_fit\n",
      "82375\t0.71\t/home/hung/PycharmProjects/federated-learning/venv/bin/python -m ipykernel_launcher -f /home/hung/.l...\n",
      "3958\t0.37\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "10107\t0.37\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "65014\t0.23\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "3308\t0.19\t/opt/google/chrome/chrome\n",
      "43594\t0.18\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "ERROR flwr 2023-06-09 17:37:31,553 | ray_client_proxy.py:87 | Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 10.10.12.34, ID: efc616ad18ed9b7fc1436ea140a65ab128bcac37f2d9dbae16ef51f0) where the task (task ID: 472ca196e19cc323924e366a03fdc5012929390f01000000, name=launch_and_fit, pid=82656, memory used=1.67GB) was running was 14.65GB / 15.39GB (0.951679), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1a1c16fdda75893afc90a953ef848e6c3fa5a580ca3d71d696d1fbe4) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.10.12.34`. To see the logs of the worker, use `ray logs worker-1a1c16fdda75893afc90a953ef848e6c3fa5a580ca3d71d696d1fbe4*out -ip 10.10.12.34. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "8425\t2.84\t/snap/pycharm-professional/336/jbr/bin/java -classpath /snap/pycharm-professional/336/lib/app.jar:/s...\n",
      "82657\t1.70\tray::launch_and_fit\n",
      "82656\t1.67\tray::launch_and_fit\n",
      "82375\t0.96\t/home/hung/PycharmProjects/federated-learning/venv/bin/python -m ipykernel_launcher -f /home/hung/.l...\n",
      "3958\t0.37\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "10107\t0.37\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "65014\t0.23\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "3308\t0.20\t/opt/google/chrome/chrome\n",
      "43594\t0.18\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "2570\t0.14\t/usr/bin/gnome-shell\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m [2023-06-09 17:37:47,001 E 82573 82573] (raylet) node_manager.cc:3069: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: efc616ad18ed9b7fc1436ea140a65ab128bcac37f2d9dbae16ef51f0, IP: 10.10.12.34) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.10.12.34`\n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m \n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "ERROR flwr 2023-06-09 17:38:48,294 | ray_client_proxy.py:87 | Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 10.10.12.34, ID: efc616ad18ed9b7fc1436ea140a65ab128bcac37f2d9dbae16ef51f0) where the task (task ID: 2ac7f7bfaa3b6218d20893452f7e306d28e2e8cb01000000, name=launch_and_fit, pid=82657, memory used=3.58GB) was running was 14.63GB / 15.39GB (0.950158), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 4c2ba05c87dd67b91139954991ae7f33bc5434c7c5b472f4a2497dc1) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.10.12.34`. To see the logs of the worker, use `ray logs worker-4c2ba05c87dd67b91139954991ae7f33bc5434c7c5b472f4a2497dc1*out -ip 10.10.12.34. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "82657\t3.58\tray::launch_and_fit\n",
      "8425\t2.72\t/snap/pycharm-professional/336/jbr/bin/java -classpath /snap/pycharm-professional/336/lib/app.jar:/s...\n",
      "82375\t1.22\t/home/hung/PycharmProjects/federated-learning/venv/bin/python -m ipykernel_launcher -f /home/hung/.l...\n",
      "3958\t0.37\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "10107\t0.37\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "65014\t0.23\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "3308\t0.20\t/opt/google/chrome/chrome\n",
      "43594\t0.18\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "2570\t0.14\t/usr/bin/gnome-shell\n",
      "41632\t0.13\t/opt/google/chrome/chrome --type=renderer --crashpad-handler-pid=3317 --enable-crash-reporter=, --ch...\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 15\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Pass parameters to the Strategy for server-side parameter initialization\u001B[39;00m\n\u001B[1;32m      6\u001B[0m strategy \u001B[38;5;241m=\u001B[39m fl\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mFedAvg(\n\u001B[1;32m      7\u001B[0m     fraction_fit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m,\n\u001B[1;32m      8\u001B[0m     fraction_evaluate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     initial_parameters\u001B[38;5;241m=\u001B[39mfl\u001B[38;5;241m.\u001B[39mcommon\u001B[38;5;241m.\u001B[39mndarrays_to_parameters(params),\n\u001B[1;32m     13\u001B[0m )\n\u001B[0;32m---> 15\u001B[0m \u001B[43msimulate_cifar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnet\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/federated-learning/main.py:17\u001B[0m, in \u001B[0;36msimulate_cifar\u001B[0;34m(strategy, net)\u001B[0m\n\u001B[1;32m     14\u001B[0m     client_resources \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_gpus\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m}\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Start simulation\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcid\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mclient_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalloaders\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_clients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_CLIENTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mServerConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Just three rounds\u001B[39;49;00m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_resources\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_resources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/federated-learning/venv/lib/python3.10/site-packages/flwr/simulation/app.py:197\u001B[0m, in \u001B[0;36mstart_simulation\u001B[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001B[0m\n\u001B[1;32m    194\u001B[0m     initialized_server\u001B[38;5;241m.\u001B[39mclient_manager()\u001B[38;5;241m.\u001B[39mregister(client\u001B[38;5;241m=\u001B[39mclient_proxy)\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m hist \u001B[38;5;241m=\u001B[39m \u001B[43m_fl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialized_server\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialized_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m event(EventType\u001B[38;5;241m.\u001B[39mSTART_SIMULATION_LEAVE)\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hist\n",
      "File \u001B[0;32m~/PycharmProjects/federated-learning/venv/lib/python3.10/site-packages/flwr/server/app.py:217\u001B[0m, in \u001B[0;36m_fl\u001B[0;34m(server, config)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fl\u001B[39m(\n\u001B[1;32m    213\u001B[0m     server: Server,\n\u001B[1;32m    214\u001B[0m     config: ServerConfig,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m History:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# Fit model\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m     hist \u001B[38;5;241m=\u001B[39m \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mround_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapp_fit: losses_distributed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(hist\u001B[38;5;241m.\u001B[39mlosses_distributed))\n\u001B[1;32m    219\u001B[0m     log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapp_fit: metrics_distributed_fit \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(hist\u001B[38;5;241m.\u001B[39mmetrics_distributed_fit))\n",
      "File \u001B[0;32m~/PycharmProjects/federated-learning/venv/lib/python3.10/site-packages/flwr/server/server.py:106\u001B[0m, in \u001B[0;36mServer.fit\u001B[0;34m(self, num_rounds, timeout)\u001B[0m\n\u001B[1;32m    102\u001B[0m start_time \u001B[38;5;241m=\u001B[39m timeit\u001B[38;5;241m.\u001B[39mdefault_timer()\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m current_round \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_rounds \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;66;03m# Train model and replace previous global model\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     res_fit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_round\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurrent_round\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res_fit:\n\u001B[1;32m    108\u001B[0m         parameters_prime, fit_metrics, _ \u001B[38;5;241m=\u001B[39m res_fit  \u001B[38;5;66;03m# fit_metrics_aggregated\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/federated-learning/venv/lib/python3.10/site-packages/flwr/server/server.py:227\u001B[0m, in \u001B[0;36mServer.fit_round\u001B[0;34m(self, server_round, timeout)\u001B[0m\n\u001B[1;32m    218\u001B[0m log(\n\u001B[1;32m    219\u001B[0m     DEBUG,\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_round \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: strategy sampled \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m clients (out of \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client_manager\u001B[38;5;241m.\u001B[39mnum_available(),\n\u001B[1;32m    224\u001B[0m )\n\u001B[1;32m    226\u001B[0m \u001B[38;5;66;03m# Collect `fit` results from all clients participating in this round\u001B[39;00m\n\u001B[0;32m--> 227\u001B[0m results, failures \u001B[38;5;241m=\u001B[39m \u001B[43mfit_clients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_instructions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_instructions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m log(\n\u001B[1;32m    233\u001B[0m     DEBUG,\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_round \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m received \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m results and \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m failures\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28mlen\u001B[39m(failures),\n\u001B[1;32m    238\u001B[0m )\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# Aggregate training results\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/federated-learning/venv/lib/python3.10/site-packages/flwr/server/server.py:334\u001B[0m, in \u001B[0;36mfit_clients\u001B[0;34m(client_instructions, max_workers, timeout)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m concurrent\u001B[38;5;241m.\u001B[39mfutures\u001B[38;5;241m.\u001B[39mThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mmax_workers) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m    330\u001B[0m     submitted_fs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    331\u001B[0m         executor\u001B[38;5;241m.\u001B[39msubmit(fit_client, client_proxy, ins, timeout)\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m client_proxy, ins \u001B[38;5;129;01min\u001B[39;00m client_instructions\n\u001B[1;32m    333\u001B[0m     }\n\u001B[0;32m--> 334\u001B[0m     finished_fs, _ \u001B[38;5;241m=\u001B[39m \u001B[43mconcurrent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubmitted_fs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Handled in the respective communication stack\u001B[39;49;00m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;66;03m# Gather results\u001B[39;00m\n\u001B[1;32m    340\u001B[0m results: List[Tuple[ClientProxy, FitRes]] \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:307\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(fs, timeout, return_when)\u001B[0m\n\u001B[1;32m    303\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001B[1;32m    305\u001B[0m     waiter \u001B[38;5;241m=\u001B[39m _create_and_install_waiters(fs, return_when)\n\u001B[0;32m--> 307\u001B[0m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fs:\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m f\u001B[38;5;241m.\u001B[39m_condition:\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from model import Net\n",
    "net = VGG16().to(DEVICE)\n",
    "params = net.get_parameters()\n",
    "\n",
    "# Pass parameters to the Strategy for server-side parameter initialization\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    ")\n",
    "\n",
    "simulate_cifar(strategy, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
